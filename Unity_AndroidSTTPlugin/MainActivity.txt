// 패키지 명은 유니티 프로젝트의 패키지명과 일치시킨다.
package com.Morph.HoloBox;

import android.annotation.SuppressLint;
import android.app.Activity;
import android.content.Context;
import android.content.Intent;
import android.os.Bundle;

// 유니티
import com.unity3d.player.UnityPlayerActivity;
import com.unity3d.player.UnityPlayer;

import android.os.Handler;
import android.os.Message;

// 음성인식
import android.speech.RecognitionListener;
import android.speech.RecognizerIntent;
import android.speech.SpeechRecognizer;

import android.util.Log;

import java.util.ArrayList;

public class MainActivity extends UnityPlayerActivity
{
    // 유니티에서 스크립트가 붙을 오브젝트 이름.
    private String UnityObjName = "pluginUnity";

    // 유니티에서 에러메세지 받을 함수 이름.
    private  String UnityMsg = "msgUnity";

    // 유니티에서 음성인식 결과를 받을 함수 이름.
    private  String UnitySTTResult = "sttUnity";

    // 핸들러 관련.
    private final int STTSTART = 1;
    private final int STTREADY = 2;
    private final int STTEND = 3;
    private msgHandler mHandler = null;

    // 음성인식 관련.
    private  SpeechRecognizer recognizer;
    private  static Context context;
    private String recogLang = "en-US";

    // 유니티에서 안드로이드 음성인식을 하려면 멀티 쓰레딩을 해야한다.
    // 그렇기 때문에 핸들러를 사용한다.

    class msgHandler extends Handler
    {
        @Override
        public void handleMessage(Message msg)
        {
            super.handleMessage(msg);
            switch (msg.what)
            {
                case STTREADY:
                    // 유니티에 음성인식이 시작했다는 메세지를 보냄.
                    UnityPlayer.UnitySendMessage(UnityObjName, UnityMsg, "START");
                    break;
                case  STTSTART:
                    // 실제 음성인식 작동 부분.
                    StartSpeechRecoService();
                    break;
                case STTEND:
                    // 유니티에 음성인식을 종료했다는 메세지를 보냄.
                    UnityPlayer.UnitySendMessage(UnityObjName, UnityMsg, "END");
                    break;
            }
        }
    }

    // 음성인식 리스너.
    private  RecognitionListener listener = new RecognitionListener()
    {
        @Override
        public void onReadyForSpeech(Bundle params) {
            // 음성인식이 작동하면 여기가 호출된다.
            mHandler.sendEmptyMessage(STTREADY);
        }

        @Override
        public void onBeginningOfSpeech() {

        }

        @Override
        public void onRmsChanged(float rmsdB) {

        }

        @Override
        public void onBufferReceived(byte[] buffer) {

        }

        @Override
        public void onEndOfSpeech() {
            // 음성인식이 끝나면 여기가 호출된다.
            mHandler.sendEmptyMessage(STTEND);
        }

        @Override
        public void onError(int error)
        {
            // 음성인식이 실패하면 나오는 에러.
            String errMsg = "";
            switch (error)
            {
                case 1: errMsg = "ERROR_NETWORK_TIMEOUT"; break;
                case 2: errMsg = "ERROR_NETWORK"; break;
                case 3: errMsg = "ERROR_AUDIO"; break;
                case 4: errMsg = "ERROR_SERVER"; break;
                case 5: errMsg = "ERROR_CLIENT"; break;
                case 6: errMsg = "ERROR_SPEECH_TIMEOUT"; break;
                case 7: errMsg = "ERROR_RECOGNIZER_BUSY"; break;
            }

            try
            {
                UnityPlayer.UnitySendMessage(UnityObjName, UnityMsg, errMsg);
            }
            catch (Exception e){
            }
        }

        @Override
        public void onResults(Bundle results)
        {
            // 음성인식 결과.
            mHandler.removeMessages(0);
            ArrayList matches = results.getStringArrayList("results_recognition");
            if(matches != null)
            {
                try
                {
                    UnityPlayer.UnitySendMessage(UnityObjName, UnitySTTResult, (String)matches.get(0));
                }
                catch (Exception e){
                }
            }
        }

        @Override
        public void onPartialResults(Bundle partialResults) {

        }

        @Override
        public void onEvent(int eventType, Bundle params) {

        }
    };

    // 초기화.
    @Override
    protected  void onCreate(Bundle savedInstanceState)
    {
        super.onCreate(savedInstanceState);

        // 핸들러를 붙인다.
        mHandler = new msgHandler();

        // 음성인식 리스너를 등록한다.
        context = getApplicationContext();
        if(recognizer == null)
        {
            recognizer = SpeechRecognizer.createSpeechRecognizer(context);
            recognizer.setRecognitionListener(listener);
        }

    }


    // 유니티에서 호출할 함수.
    public void StartSpeechReco(String _lang)
    {
        // "ko-KR : 한국어 / "en-US" :  미국영어 /
        recogLang = _lang;

        EndSpeechReco();

        // 핸들러에 시작을 알림.
        try{
            Message msg1 = new Message();
            msg1.what = STTSTART;
            mHandler.sendMessage(msg1);
        }
        catch (Exception e){
        }
    }

    // 실제 음성인식을 호출한다. "recogLang" 은 음성인식 할 언어로 하면된다.
    public void StartSpeechRecoService()
    {
        Intent i = new Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH); // 음성인식.
        i.putExtra(RecognizerIntent.EXTRA_CALLING_PACKAGE, getPackageName());
        i.putExtra(RecognizerIntent.EXTRA_LANGUAGE, recogLang);
        recognizer.startListening(i);
    }

    // 메세지 초기화.
    public void EndSpeechReco()
    {
        this.mHandler.removeMessages(STTREADY);
        this.mHandler.removeMessages(STTSTART);
        this.mHandler.removeMessages(STTEND);
    }

}
